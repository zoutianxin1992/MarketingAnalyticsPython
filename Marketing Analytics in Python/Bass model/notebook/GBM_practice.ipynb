{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da153045-8916-44fc-af10-da91fc8e3e04",
   "metadata": {},
   "source": [
    "# Generalized Bass Model (Practice: Color TV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa62faf-876e-4ea9-9b8b-92dd91207947",
   "metadata": {},
   "source": [
    "Generalized Bass model allows to estimate how marketing mix variables (e.g., price, ad spending) affect product diffussion.\n",
    "$$\\hat{A}(t) = M\\cdot\\frac{1-exp(-(p+q)t^*)}{1+\\frac{q}{p}exp(-(p+q)t^*)}$$ <br>\n",
    "where $t^* = t + b1\\cdot ln(\\frac{price(t)}{price(1)}) + p2\\cdot ln(\\frac{adv(t)}{adv(1)}) $ is the **effective diffussion time**.\n",
    "\n",
    "$$\\hat{N}(t) = \\hat{A}(t)-\\hat{A}(t-1)$$ <br>\n",
    "\n",
    "The only difference between GBM and vanilla BM is that GBM adjusts time to **\"effective time\"**, which accounts for the impact of marketing mixes. GBM also has two more parameters: price impact $b1$ and advertising impact $b2$. You need to have marketing mix data to use GBM, and it's ok to include only price or only advertising."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37412c5-01ac-4c43-80d6-0faaed404363",
   "metadata": {},
   "source": [
    "The dataset [3-4 GBM-Color TV](https://github.com/zoutianxin1992/MarketingAnalyticsPython/blob/main/Marketing%20Analytics%20in%20Python/Bass%20model/Dataset/3-4%20GBM%20ColorTV.csv) contains the color TV's price and sales data from year 1961 to 1970. Let us use GBM to predict TV's sales in 1971-1973. Assume the prices will be 485,470, and 455 for the three years.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395355df-40d8-43c8-919f-9ffe1b68b772",
   "metadata": {},
   "source": [
    "## Estimate GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ebda1-12c0-4250-bcdb-5d67c7ba84c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages and data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import least_squares                 # package to conduct Nonlinear least square \n",
    "\n",
    "# import historical data \n",
    "url = \"https://raw.githubusercontent.com/zoutianxin1992/MarketingAnalyticsPython/main/Marketing%20Analytics%20in%20Python/Bass%20model/Dataset/3-4%20GBM%20ColorTV.csv\"\n",
    "df = pd.read_csv(url) \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976856f3-5eca-4122-82d6-80704f631907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the variables to t, N, and Price\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a472a29-89d5-4c94-be4e-50eb575ff2c0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Rename the variables to t, N, and Price\n",
    "# df.rename(columns = {df.columns[1]:\"t\",df.columns[2]:\"N\",df.columns[3]:\"Price\"}, inplace = True)  # \"inplace\" apply the name change to df itself \n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de86659-7406-42bb-9c77-739aa95c04c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define A_hat(t) and N_hat(t)\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec4e5ac-edd7-4851-9413-e0d39beb65eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # define A_hat(t) and N_hat(t)\n",
    "# # Remember GBM has an additional variable (Price) and an additional parameter (b1)\n",
    "# Price_1 = df['Price'][0]\n",
    "# def A_hat(t,Price,p,q,M,b1):                                     # two more arguments: Price and b1\n",
    "#     tstar = t + b1 * np.log(Price/Price_1)                        #tstar: effective time\n",
    "#     return M * (1 - np.exp(-(p+q)*tstar))/(1 + q / p* np.exp(-(p+q)*tstar))    # the \"t\" in BM is replaced with \"t*\" in GBM\n",
    "\n",
    "# # define N_hat(t) \n",
    "# def N_hat(t,Price,p,q,M,b1):  \n",
    "#     return A_hat(t,Price,p,q,M,b1) - A_hat(t-1,Price,p,q,M,b1)  # We can use the A_hat function instead of manually typing the formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49cc94-9bd4-4e35-89ee-418a7a3a4dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define prediction errors as a fucntion of p,q,M, and b1\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ce8b2-dede-4230-95af-4ce10cc6eee4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # define prediction errors as a fucntion of p,q,M, and b1\n",
    "# T = len(df['N'])   # number of periods for historical data\n",
    "\n",
    "\n",
    "# def prediction_error(params):   # Note that we input p,q,M,b1 as a 1*4 array \"params.\"  \n",
    "#     p = params[0]\n",
    "#     q = params[1]\n",
    "#     M = params[2]\n",
    "#     b1 = params[3]\n",
    "#     Nhat = [N_hat(t,df['Price'][t-1],p,q,M,b1) for t in range(1,T+1)]            # Given p,q,M, generate Bass prediction for each period\n",
    "#     return df['N'] - Nhat                                 # Prediction error for each period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0ad21f-ef35-41e6-a0fd-2bb99e275275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate p,q,M,b1 using least_squares, and store estimated parameters\n",
    "# Bass model requires 0<p<1, 0<q<1, M>0, and b1<0 so we need to add the constraints\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae22104-7fc4-4c14-9905-c29ce0e59896",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # estimate p,q,M,b1 using least_squares\n",
    "# # Bass model requires 0<p<1, 0<q<1, M>0, and b1<0 so we need to add the constraints\n",
    "# A_t = sum(df['N'])           # calculate already adopters until period t\n",
    "# params0 = [0.01,0.16,3*A_t,-0.3]  # initial guess for p,q,M, b1. Required by least_squares\n",
    "# estim_results= least_squares(prediction_error, params0, bounds = ([0,0,0,-np.Inf],[np.Inf,np.Inf,np.Inf,0]) )\n",
    "\n",
    "# #########################\n",
    "# # prediction_error: an array of prediction errors for each period\n",
    "# # param0: initial guesses\n",
    "# # bounds: The bounds for p,q,M, and b1. In our case p,q,M>0 and b1<0\n",
    "\n",
    "# #store estimated parameters\n",
    "# p_estim = estim_results.x[0]\n",
    "# q_estim = estim_results.x[1]\n",
    "# M_estim = estim_results.x[2]\n",
    "# b1_estim = estim_results.x[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88457a4b-3c0a-4c26-9898-c1b9a491cb68",
   "metadata": {},
   "source": [
    "## Predict future sales for the next three periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9449015c-7928-4cbe-9817-4e95a172b4d4",
   "metadata": {},
   "source": [
    "Historical sales data have 10 periods. We will predict the sales for period 11-13 (year 1971-1973), assuming the prices will be 485, 470, and 455. Plot the sales predictions (N(t)) of period 1-13 in a chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8246b-a988-4709-a3f0-ef20d3e61350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an array of prices for period 1-13\n",
    "# predict the sales in period 1-13 using Bass model\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b08e5dd-68db-4959-b0ba-9944bad1facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predicted and actual sales trajectory for period 1-13 \n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d83339-eae7-4e28-8a40-521c114c80f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Appending the future prices to the historical price data\n",
    "# Price_13 = df[\"Price\"].append(pd.Series([485,470,455]))\n",
    "# T_pred = 13  # number of periods for prediction\n",
    "# # gen\n",
    "# predictA = [A_hat(t,Price_13.iloc[t-1],p_estim,q_estim,M_estim,b1_estim) for t in range(1,T_pred+1)]  # predict already adopters for T periods\n",
    "# predictN = [N_hat(t,Price_13.iloc[t-1],p_estim,q_estim,M_estim,b1_estim) for t in range(1,T_pred+1)]  # predict already adopters for T periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4839ed0d-73ad-4edd-8246-7d82bc0c4edd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Plot the trajectory of new adopters\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = [12,8]  # set figure size to be 12*8 inch\n",
    "# plt.plot(range(1,T_pred+1),predictN)\n",
    "# plt.scatter(range(1,T+1),df[\"N\"],color = \"red\")    # Also plot historical sales data\n",
    "# plt.xticks(range(1,T_pred+1,2), fontsize = 18)\n",
    "# plt.yticks(fontsize = 18)\n",
    "# plt.ylabel(\"New adopters\",fontsize = 18)\n",
    "# plt.xlabel(\"time\", fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086fb1c6-e560-4b56-a3eb-051953c94099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
